# ==============================================================================
# NGINX Configuration for OpenAI Forward Multi-User Service
# ==============================================================================
# Description: NGINX reverse proxy and load balancer for multi-user AI services
# Author: Assistant
# Created: 2024-12-19
# Version: 1.0
#
# Features:
# - Reverse proxy for all AI services
# - Load balancing for high availability
# - Rate limiting for multi-user support
# - SSL termination ready
# - Connection pooling and optimization
# - Static file serving for WebUI assets
# ==============================================================================

# Worker processes configuration
worker_processes auto;
worker_rlimit_nofile 65535;

# Events block - connection handling
events {
    worker_connections 4096;
    use epoll;
    multi_accept on;
}

# HTTP block - main configuration
http {
    # Basic settings
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    charset utf-8;
    
    # Logging configuration with timestamps
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                   '$status $body_bytes_sent "$http_referer" '
                   '"$http_user_agent" "$http_x_forwarded_for" '
                   'rt=$request_time uct="$upstream_connect_time" '
                   'uht="$upstream_header_time" urt="$upstream_response_time"';
    
    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;
    
    # Performance optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    keepalive_requests 1000;
    client_max_body_size 100M;
    client_body_timeout 60s;
    client_header_timeout 60s;
    send_timeout 60s;
    
    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;
    
    # Rate limiting zones for multi-user support
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/m;
    limit_req_zone $binary_remote_addr zone=chat_limit:10m rate=60r/m;
    limit_req_zone $binary_remote_addr zone=webui_limit:10m rate=30r/m;
    limit_conn_zone $binary_remote_addr zone=conn_limit:10m;
    
    # Upstream definitions for load balancing
    upstream ai_router_backend {
        least_conn;
        server smart-ai-router:9000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }
    
    upstream openai_forward_backend {
        least_conn;
        server openai-forward-proxy:8000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }
    
    upstream webui_backend {
        least_conn;
        server openai-forward-webui:8001 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }
    
    upstream ollama_backend {
        least_conn;
        server ollama-server:11434 max_fails=3 fail_timeout=30s;
        keepalive 16;
    }
    
    # Main server block
    server {
        listen 80;
        listen [::]:80;
        server_name localhost;
        
        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;
        
        # Connection limits
        limit_conn conn_limit 50;
        
        # Health check endpoint
        location /nginx-health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
        
        # AI Router - Primary API endpoint (推荐使用)
        location /api/ {
            # Rate limiting for API calls
            limit_req zone=api_limit burst=20 nodelay;
            
            # Proxy settings
            proxy_pass http://ai_router_backend/;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            proxy_buffering off;
            
            # Timeout settings for AI responses
            proxy_connect_timeout 10s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;
        }
        
        # Direct AI Router access (alternative)
        location /v1/ {
            limit_req zone=chat_limit burst=10 nodelay;
            
            proxy_pass http://ai_router_backend/v1/;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            proxy_buffering off;
            
            proxy_connect_timeout 10s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;
        }
        
        # Health and stats endpoints
        location ~ ^/(health|stats)$ {
            proxy_pass http://ai_router_backend$request_uri;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            proxy_connect_timeout 5s;
            proxy_send_timeout 10s;
            proxy_read_timeout 10s;
        }
        
        # OpenAI Forward direct access
        location /forward/ {
            limit_req zone=api_limit burst=15 nodelay;
            
            proxy_pass http://openai_forward_backend/;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            proxy_buffering off;
            
            proxy_connect_timeout 10s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;
        }
        
        # Service-specific endpoints
        location ~ ^/(deepseek|lingyiwanwu|ollama)/ {
            limit_req zone=chat_limit burst=10 nodelay;
            
            proxy_pass http://openai_forward_backend$request_uri;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            proxy_buffering off;
            
            proxy_connect_timeout 10s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;
        }
        
        # WebUI Management Interface
        location /webui/ {
            limit_req zone=webui_limit burst=5 nodelay;
            
            proxy_pass http://webui_backend/;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            
            # Special handling for Streamlit
            proxy_set_header X-Forwarded-Host $host;
            proxy_set_header X-Forwarded-Server $host;
            
            proxy_connect_timeout 10s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }
        
        # Ollama direct access
        location /ollama-direct/ {
            limit_req zone=api_limit burst=10 nodelay;
            
            proxy_pass http://ollama_backend/;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            proxy_buffering off;
            
            proxy_connect_timeout 10s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;
        }
        
        # Static files and assets
        location /static/ {
            expires 1h;
            add_header Cache-Control "public, immutable";
        }
        
        # Default route - redirect to WebUI
        location = / {
            return 302 /webui/;
        }
        
        # 404 error handling
        location / {
            return 404 '{"error": "Not Found", "message": "Please use /api/, /v1/, /webui/, or specific service endpoints"}';
            add_header Content-Type application/json;
        }
    }
    
    # HTTPS server block (ready for SSL certificates)
    # server {
    #     listen 443 ssl http2;
    #     listen [::]:443 ssl http2;
    #     server_name localhost;
    #     
    #     # SSL configuration
    #     ssl_certificate /etc/nginx/ssl/cert.pem;
    #     ssl_certificate_key /etc/nginx/ssl/key.pem;
    #     ssl_protocols TLSv1.2 TLSv1.3;
    #     ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
    #     ssl_prefer_server_ciphers off;
    #     
    #     # Include the same location blocks as HTTP server
    #     include /etc/nginx/conf.d/locations.conf;
    # }
}

# ==============================================================================
# Usage Instructions:
#
# 1. Primary API Access (Recommended):
#    http://localhost/api/v1/chat/completions
#    - Load balanced and rate limited
#    - Automatic failover
#    - Optimal for production use
#
# 2. Direct Service Access:
#    - DeepSeek: http://localhost/deepseek/v1/chat/completions
#    - LingyiWanwu: http://localhost/lingyiwanwu/v1/chat/completions
#    - Ollama: http://localhost/ollama/v1/chat/completions
#
# 3. Management Interface:
#    http://localhost/webui/
#
# 4. Health Monitoring:
#    - NGINX: http://localhost/nginx-health
#    - Services: http://localhost/health
#    - Statistics: http://localhost/stats
#
# Rate Limits:
# - API calls: 100 requests/minute per IP
# - Chat completions: 60 requests/minute per IP  
# - WebUI: 30 requests/minute per IP
# - Max connections: 50 per IP
# ============================================================================== 